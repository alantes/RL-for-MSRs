The files are supplementary code and related data for the cases present in "Adaptive actuation of magnetic soft robot using deep reinforcement learning".

The files in after_finetuned are the ones for generating fields; while the files in before_finetuned are the ones for training. The former ones have exact gravitational acceleration and density paramters while the latter ones have smaller gravitational acceleration and larger density paramters (gravities remain the same), which is for acceleration training due to the difficulties we found of PyElastica handing cases where small-scale rods are used.

Files in each folder include:
- `buffer.py`: the replay buffer of RL agents.
- `Damping.py`: the damping force we introduce in our work based on relative speeds. (However, we still apply slight original damping forces acting on the translational velocities because we find that when elements are not separated finely enough, the robots will slowly slide on the ground due to bugs. This part of damping are small enough to bring little influce to overall motion or movement.)
- `data` folder:
	- `arm_data.npz`: data of robot positions. We use the file for rendering.
	- `arm_activation.npz`: data of fields. Should be removed.
- `magnetic_field.csv`: discrete points of magnetic fields. 100 points per second.
- `magnetic_field.py`: the `MagneticField` object we use for easier initialization, update and reading components.
- `MagneticTorques.py`: the magnetic torques we introduce to simulate the interaction between magnetic soft robots and external fields.
- `main.py`: the file for training. To use it, type `python3.8 main.py` in terminals.
- `modelsreload.py`: the file for loading trained RL agents and, in the meantime, generate a simple .mp4 file as well as store fields. To use it, type `python3.8 modelsreload.py` in terminals.
- `movinggaits.mp4`: the .mp4 file generated by `modelsreload.py`. For more elegant visualizations please use professional animation softwares for rendering. We use blender.
- `networks.py`: the networks of RL agents.
- `plots` folder: learning curves plotted by `plot_learning_curve()` in `utils.py`.
- `reward.csv`: rewards stored while training.
- `post_processing.py`: the file for generating .mp4 files above.
- `set_environment.py`: the environment where trainings take place.
- `td3_torch.py`: the TD3 implementations of RL agents.
- `tmp` folder: trained models.
- `utils.py`: codes for utilities.
